{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0630 13:21:44.858083 25208 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0630 13:21:45.245903 25208 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0630 13:21:45.350414 25208 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0630 13:21:45.652333 25208 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0630 13:21:45.780254 25208 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0630 13:21:45.813841 25208 deprecation.py:506] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0630 13:21:45.922418 25208 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0630 13:21:46.135302 25208 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "W0630 13:21:46.191333 25208 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0630 13:21:46.202335 25208 deprecation.py:323] From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train images...\n",
      "(17, 512, 512, 3)\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(17, 512, 512, 3)\n",
      "Train on 13 samples, validate on 4 samples\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 268s 21s/step - loss: 0.7609 - acc: 0.8211 - val_loss: 0.4999 - val_acc: 0.7861\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.76091, saving model to unet.hdf5\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 239s 18s/step - loss: 0.5386 - acc: 0.8211 - val_loss: 0.5101 - val_acc: 0.7861\n",
      "\n",
      "Epoch 00002: loss improved from 0.76091 to 0.53856, saving model to unet.hdf5\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 232s 18s/step - loss: 0.5155 - acc: 0.8211 - val_loss: 0.4940 - val_acc: 0.7861\n",
      "\n",
      "Epoch 00003: loss improved from 0.53856 to 0.51554, saving model to unet.hdf5\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 237s 18s/step - loss: 0.4834 - acc: 0.8211 - val_loss: 0.4693 - val_acc: 0.7861\n",
      "\n",
      "Epoch 00004: loss improved from 0.51554 to 0.48337, saving model to unet.hdf5\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 230s 18s/step - loss: 0.4507 - acc: 0.8211 - val_loss: 0.4633 - val_acc: 0.7861\n",
      "\n",
      "Epoch 00005: loss improved from 0.48337 to 0.45069, saving model to unet.hdf5\n",
      "predict test data\n",
      "10/10 [==============================] - 31s 3s/step\n",
      "array to image\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import array_to_img\n",
    "import cv2\n",
    "from data import *\n",
    "\n",
    "\n",
    "class myUnet(object):\n",
    "    def __init__(self, img_rows=512, img_cols=512):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "\n",
    "    def load_data(self):\n",
    "        mydata = dataProcess(self.img_rows, self.img_cols)\n",
    "        imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "        imgs_test = mydata.load_test_data()\n",
    "        return imgs_train, imgs_mask_train, imgs_test\n",
    "\n",
    "    def get_unet(self):\n",
    "        inputs = Input((self.img_rows, self.img_cols, 3))\n",
    "\n",
    "        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "        conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "        conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "        conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "        drop4 = Dropout(0.5)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "        drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "        up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "            UpSampling2D(size=(2, 2))(drop5))\n",
    "        merge6 = concatenate([drop4, up6], axis=3)\n",
    "        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "        up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "            UpSampling2D(size=(2, 2))(conv6))\n",
    "        merge7 = concatenate([conv3, up7], axis=3)\n",
    "        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "        up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "            UpSampling2D(size=(2, 2))(conv7))\n",
    "        merge8 = concatenate([conv2, up8], axis=3)\n",
    "        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "        up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "            UpSampling2D(size=(2, 2))(conv8))\n",
    "        merge9 = concatenate([conv1, up9], axis=3)\n",
    "        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "        conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "        model = Model(input=inputs, output=conv10)\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "       # print(\"loading data\")\n",
    "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        print(imgs_train.shape)\n",
    "       # print(\"loading data done\")\n",
    "        model = self.get_unet()\n",
    "       # print(\"got unet\")\n",
    "        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', verbose=1, save_best_only=True)\n",
    "       # print('Fitting model...')\n",
    "        model.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=5, verbose=1,\n",
    "                  validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "        print('predict test data')\n",
    "        imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "        np.save('./results/imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    def save_img(self):\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load('./results/imgs_mask_test.npy')\n",
    "        piclist = []\n",
    "        for line in open(\"./results/pic.txt\"):\n",
    "            line = line.strip()\n",
    "            picname = line.split('/')[-1]\n",
    "            piclist.append(picname)\n",
    "        for i in range(imgs.shape[0]):\n",
    "            path = \"./results/\" + piclist[i]\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(path)\n",
    "            cv_pic = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            cv_pic = cv2.resize(cv_pic,(1918,1280),interpolation=cv2.INTER_CUBIC)\n",
    "            binary, cv_save = cv2.threshold(cv_pic, 127, 255, cv2.THRESH_BINARY)\n",
    "            cv2.imwrite(path, cv_save)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    myunet = myUnet()\n",
    "    model = myunet.get_unet()\n",
    "    # model.summary()\n",
    "    # plot_model(model, to_file='model.png')\n",
    "    myunet.train()\n",
    "    myunet.save_img()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array to image\n"
     ]
    }
   ],
   "source": [
    "myunet.save_img()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
